# Regularization

## Topics covered in today's module
* L1/L2 Regularization
* Dropout
* Overfitting
* Underfitting

## Main takeaways from doing today's assignment
- Regularization techniques, like L1 and L2, are used to prevent overfitting in machine learning models.
    - **L1 regularization (Lasso)**:
        - Adds the absolute value of the weights to the loss function.
        - Encourages sparsity in the model parameters (pushes some weights to zero).
        - Useful for feature selection and creating simpler, more interpretable models.
    - **L2 regularization (Ridge)**:
        - Adds the square of the weights to the loss function.
        - Spreads out weights more evenly across all features.
        - Useful when dealing with multicollinearity (highly correlated features).


## Challenging, interesting, or exciting aspects of today's assignment
Plotting graphs can be a little confusing!
