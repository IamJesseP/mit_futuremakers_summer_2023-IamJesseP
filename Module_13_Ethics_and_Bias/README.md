# Ethics and Bias

## Topics covered in today's module
* Data Ethics
* Feedback loops
* Bias

## Main takeaways from doing today's assignment
- Machine learning models can unintentionally perpetuate and amplify biases present in their training data.
- Biases in machine learning can take various forms, including historical bias, representation bias, measurement bias, aggregation bias, evaluation bias, and deployment bias.
- To mitigate data bias, it's crucial to ensure that the training data accurately represents the different subgroups within the population that the model will be applied to.
- Diverse teams can identify ethical problems earlier and consider a wider range of solutions, leading to more effective and equitable machine learning models.
- Biased decisions in hiring algorithms can be caused by biased human decisions in the training data or by certain attributes disproportionately affecting the outcomes.

## Challenging, interesting, or exciting aspects of today's assignment
- It's exciting to see that this is a recognized issue that is being taken seriously!

## Additional resources used 
[Surival of the Best Fit Game](https://www.survivalofthebestfit.com/game/)

[Harini Suresh and John Guttag Paper](https://arxiv.org/pdf/1901.10002.pdf)

[Teams Solve Problems Faster When Theyâ€™re More Cognitively Diverse, HBR Article](https://hbr.org/2017/03/teams-solve-problems-faster-when-theyre-more-cognitively-diverse)

[ImageNet Devopedia Article](https://devopedia.org/imagenet)
